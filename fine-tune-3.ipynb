{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec628600",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn pandas evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92ed632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\Diagnoses Prediction\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\AI\\Diagnoses Prediction\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9a94a",
   "metadata": {},
   "source": [
    "Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9db08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce GTX 1080\n",
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA not available — still CPU only\")\n",
    "\n",
    "print(torch.__version__)  # should be 2.6.0 or newer\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9c4a0",
   "metadata": {},
   "source": [
    "Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021f8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.  Lap...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.  Lap...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-Mode. Doppler.    2-D Echocardiogram - ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D Echocardiogram  2-D Echocardiogram - 2  1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  label\n",
       "0   A 23-year-old white female presents with comp...      0\n",
       "1   Consult for laparoscopic gastric bypass.  Lap...      2\n",
       "2   Consult for laparoscopic gastric bypass.  Lap...      2\n",
       "3   2-D M-Mode. Doppler.    2-D Echocardiogram - ...      3\n",
       "4   2-D Echocardiogram  2-D Echocardiogram - 2  1...      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Combine relevant columns into one input text\n",
    "df['input_text'] = (\n",
    "    df['description'].fillna('') + ' ' +\n",
    "    df['sample_name'].fillna('') + ' ' +\n",
    "    df['transcription'].fillna('') + ' ' +\n",
    "    df['keywords'].fillna('')\n",
    ")\n",
    "\n",
    "\n",
    "# Encode the target label\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['medical_specialty'])\n",
    "\n",
    "df[['input_text', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4b6da",
   "metadata": {},
   "source": [
    "Train-Test-Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2edfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['input_text', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['input_text', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3be70",
   "metadata": {},
   "source": [
    "Tokenize With BioBERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54980fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3999/3999 [00:04<00:00, 950.00 examples/s] \n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 1009.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac23a3c",
   "metadata": {},
   "source": [
    "Load Model For Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424dcd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = df['label'].nunique()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5aa0f0",
   "metadata": {},
   "source": [
    "Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4709365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b063d3a",
   "metadata": {},
   "source": [
    "Initialize Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7051b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ea8ac",
   "metadata": {},
   "source": [
    "Train BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae984ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Berat\\AppData\\Local\\Temp\\ipykernel_18128\\2133766414.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 21:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.466600</td>\n",
       "      <td>1.799394</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.559000</td>\n",
       "      <td>1.447894</td>\n",
       "      <td>0.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.256100</td>\n",
       "      <td>1.369117</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=1.760574951171875, metrics={'train_runtime': 1309.5903, 'train_samples_per_second': 9.161, 'train_steps_per_second': 1.145, 'total_flos': 3157620301651968.0, 'train_loss': 1.760574951171875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c6215",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc1b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"biobert_medical_specialty_classifier\")\n",
    "tokenizer.save_pretrained(\"biobert_medical_specialty_classifier\")\n",
    "\n",
    "# Save label encoder mapping\n",
    "import json\n",
    "# Convert NumPy integers to plain Python ints\n",
    "label_map = {cls: int(label) for cls, label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"label_mapping.json\", \"w\") as f:\n",
    "    json.dump(label_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b10325",
   "metadata": {},
   "source": [
    "Inference Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ac4352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' General Medicine'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def predict_specialty(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    pred_label = torch.argmax(outputs.logits, axis=1).item()\n",
    "    return label_encoder.inverse_transform([pred_label])[0]\n",
    "\n",
    "sample_input = \"Patient reports abdominal pain and nausea for two days.\"\n",
    "predict_specialty(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d98f28",
   "metadata": {},
   "source": [
    "Test Inference for Urology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51657ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Urology'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = \"Routine follow-up after recent surgical intervention for urinary symptoms. Post-operative Office Visit Note The patient is a 58-year-old male presenting for follow-up after undergoing transurethral resection of the prostate (TURP) two weeks ago. He reports decreased urinary urgency and nocturia, with occasional dribbling. No hematuria or dysuria noted. Physical exam was unremarkable. Bladder scan shows post-void residual volume within normal limits. Patient advised to continue tamsulosin and increase fluid intake. Will reassess in four weeks. TURP, urinary symptoms, follow-up, prostate, tamsulosin, residual volume, bladder function\"\n",
    "predict_specialty(sample_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
